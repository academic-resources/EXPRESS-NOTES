<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes"
    />
    <title>
      Leistungsspezifische Best Practices für Express-Anwendungen in
      Produktionsumgebungen
    </title>
    <style type="text/css">
      code {
        white-space: pre-wrap;
      }
      span.smallcaps {
        font-variant: small-caps;
      }
      span.underline {
        text-decoration: underline;
      }
      div.column {
        display: inline-block;
        vertical-align: top;
        width: 50%;
      }
    </style>
  </head>
  <body>
    <header id="title-block-header">
      <h1 class="title">
        Leistungsspezifische Best Practices für Express-Anwendungen in
        Produktionsumgebungen
      </h1>
    </header>
    <h1
      id="best-practices-in-produktionsumgebungen-leistung-und-zuverlässigkeit"
    >
      Best Practices in Produktionsumgebungen: Leistung und Zuverlässigkeit
    </h1>
    <h2 id="überblick">Überblick</h2>
    <p>
      In diesem Beitrag werden Best Practices in Bezug auf Leistung und
      Zuverlässigkeit für Express-Anwendungen behandelt, die in der
      Produktionsumgebung bereitgestellt werden.
    </p>
    <p>
      Dieses Thema gehört sicherlich zur “DevOps”-Welt und deckt traditionelle
      Entwicklungs- und Betriebsprozesse ab. Entsprechend sind die Informationen
      hier in zwei Teile unterteilt:
    </p>
    <ul>
      <li>
        <a href="#code">Empfehlungen für Maßnahmen an Ihrem Code</a>
        (Entwicklung).
      </li>
      <li>
        <a href="#env"
          >Empfehlungen für Maßnahmen an Ihrer Umgebung/Ihrem Setup</a
        >
        (Betrieb).
      </li>
    </ul>
    <p><a name="code"></a></p>
    <h2 id="empfehlungen-für-maßnahmen-an-ihrem-code">
      Empfehlungen für Maßnahmen an Ihrem Code
    </h2>
    <p>
      Dies sind einige Beispiele für Maßnahmen, die Sie an Ihrem Code vornehmen
      können, um die Anwendungsleistung zu verbessern:
    </p>
    <ul>
      <li>GZIP-Komprimierung verwenden</li>
      <li>Keine synchronen Funktionen verwenden</li>
      <li>Für statische Dateien Middleware verwenden</li>
      <li>Auf ordnungsgemäße Protokollierung achten</li>
      <li>Ausnahmebedingungen ordnungsgemäß handhaben</li>
    </ul>
    <h3 id="gzip-komprimierung-verwenden">GZIP-Komprimierung verwenden</h3>
    <p>
      Mit der GZIP-Komprimierung lässt sich die Größe des Antworthauptteils
      deutlich verringern und somit die Geschwindigkeit der Webanwendung
      erhöhen. Verwenden Sie die Middleware
      <a href="https://www.npmjs.com/package/compression">compression</a> für
      die GZIP-Komprimierung in Ihrer Express-Anwendung. Beispiel:
    </p>
    <pre>
<code class="language-javascript" translate="no">
var compression = require('compression');
var express = require('express');
var app = express();
app.use(compression());
</code>
</pre>
    <p>
      Bei Websites mit hohem Datenverkehr in Produktionsumgebungen lässt sich
      die Komprimierung am besten installieren, indem sie auf Reverse
      Proxy-Ebene implementiert wird (siehe
      <a href="#proxy">Reverse Proxy verwenden</a>). In diesem Fall wird die
      Middleware “compression” nicht benötigt. Details zur Aktivierung der
      GZIP-Komprimierung in Nginx siehe
      <a href="http://nginx.org/en/docs/http/ngx_http_gzip_module.html"
        >Modul ngx_http_gzip_module</a
      >
      in der Nginx-Dokumentation.
    </p>
    <h3 id="keine-synchronen-funktionen-verwenden">
      Keine synchronen Funktionen verwenden
    </h3>
    <p>
      Synchrone Funktionen und Methoden belasten den Ausführungsprozess, bis sie
      zurückgegeben werden. Ein einzelner Aufruf für eine synchrone Funktion
      kann in wenigen Mikrosekunden oder Millisekunden zurückgegeben werden. Bei
      Websites mit hohem Datenverkehr hingegen summieren sich diese Aufrufe und
      verringern die Leistung der Anwendung. Sie sollten also deren Verwendung
      in Produktionsumgebungen vermeiden.
    </p>
    <p>
      Auch wenn Node und viele andere Module synchrone und asynchrone Versionen
      ihrer Funktionen bieten, sollten Sie in Produktionsumgebungen immer die
      asynchrone Version verwenden. Nur beim ersten Systemstart ist die
      Verwendung einer synchronen Funktion begründet.
    </p>
    <p>
      Wenn Sie Node.js 4.0 und höher oder io.js 2.1.0 und höher verwenden,
      können Sie über das Befehlszeilenflag <code>--trace-sync-io</code> eine
      Warnung und einen Stack-Trace ausgeben, wenn Ihre Anwendung eine synchrone
      API verwendet. Auch wenn Sie diese natürlich nicht in der
      Produktionsumgebung verwenden werden, soll dadurch trotzdem sichergestellt
      werden, dass Ihr Code in der Produktionsumgebung eingesetzt werden kann.
      Weitere Informationen hierzu siehe
      <a
        href="https://nodejs.org/en/blog/weekly-updates/weekly-update.2015-05-22/#2-1-0"
        >Wöchentliches Update für io.js 2.1.0</a
      >.
    </p>
    <h3 id="für-statische-dateien-middleware-verwenden">
      Für statische Dateien Middleware verwenden
    </h3>
    <p>
      Bei der Entwicklung können Sie
      <a href="/%7B%7B%20page.lang%20%7D%7D/4x/api.html#res.sendFile"
        >res.sendFile()</a
      >
      für statische Dateien verwenden. Dies gilt jedoch nicht für die
      Produktionsumgebung, da diese Funktion bei jeder Dateianforderung aus dem
      Dateisystem lesen muss. Dadurch kommt es zu deutlichen Latenzen, die sich
      negativ auf die Gesamtleistung der Anwendung auswirken. Beachten Sie, dass
      <code>res.sendFile()</code> <em>nicht</em> mit dem Systemaufruf
      <a href="http://linux.die.net/man/2/sendfile">sendfile</a> implementiert
      wird, wodurch dieser deutlich effizienter wäre.
    </p>
    <p>
      Verwenden Sie stattdessen die Middleware
      <a href="https://www.npmjs.com/package/serve-static">serve-static</a>
      (oder etwas Vergleichbares), die für die Bereitstellung von Dateien für
      Express-Anwendungen optimiert ist.
    </p>
    <p>
      Die bessere Option wäre, für statische Dateien einen Reverse Proxy zu
      verwenden. Weitere Informationen siehe
      <a href="#proxy">Reverse Proxy verwenden</a>.
    </p>
    <h3 id="auf-ordnungsgemäße-protokollierung-achten">
      Auf ordnungsgemäße Protokollierung achten
    </h3>
    <p>
      Im Allgemeinen gibt es für die Protokollierung Ihrer Anwendung zwei
      Gründe: 1) Debugging und 2) Protokollierung von Anwendungsaktivitäten (im
      Wesentlichen alles andere, außer Debugging). Die Verwendung von<code
        >console.log()</code
      >
      oder <code>console.err()</code> zur Ausgabe von Protokollnachrichten an
      das Terminal ist in der Entwicklung gängige Praxis.
      <a href="https://nodejs.org/api/console.html#console_console_1"
        >Diese Funktionen sind jedoch synchron</a
      >, wenn das Ziel ein Terminal oder eine Datei ist. Sie sind also für
      Produktionsumgebungen nicht geeignet, es sei denn, Sie leiten die Ausgabe
      per Pipe zu einem anderen Programm um.
    </p>
    <h4 id="für-debuggingzwecke">Für Debuggingzwecke</h4>
    <p>
      Wenn Sie die Protokollierung für Debuggingzwecke nutzen, sollten Sie statt
      <code>console.log()</code> besser ein spezielles Debuggingmodul wie
      <a href="https://www.npmjs.com/package/debug">debug</a> verwenden. Mit
      einem solchen Modul können Sie über die Umgebungsvariable DEBUG steuern,
      welche Debugnachrichten an <code>console.err()</code> gesendet werden
      (falls vorhanden). Um Ihre Anwendung rein asynchron zu halten, können Sie
      trotzdem <code>console.err()</code> per Pipe zu einem anderen Programm
      umleiten. Sie nehmen dann aber kein Debugging in der Produktionsumgebung
      vor, richtig?
    </p>
    <h4 id="für-anwendungsaktivitäten">Für Anwendungsaktivitäten</h4>
    <p>
      Wenn Sie Anwendungsaktivitäten protokollieren (z. B. den Datenverkehr oder
      API-Aufrufe aufzeichnen), sollten Sie statt
      <code>console.log()</code> eine Protokollierungsbibliothek wie
      <a href="https://www.npmjs.com/package/winston">Winston</a> oder
      <a href="https://www.npmjs.com/package/bunyan">Bunyan</a> verwenden. Einen
      ausführlichen Vergleich dieser beiden Bibliotheken finden Sie im
      StrongLoop-Blogbeitrag
      <a
        href="https://strongloop.com/strongblog/compare-node-js-logging-winston-bunyan/"
        >Vergleich von Winston und Bunyan für die Node.js-Protokollierung</a
      >.
    </p>
    <p><a name="exceptions"></a></p>
    <h3 id="ausnahmebedingungen-ordnungsgemäß-handhaben">
      Ausnahmebedingungen ordnungsgemäß handhaben
    </h3>
    <p>
      Node-Anwendungen stürzen ab, wenn eine nicht abgefangene Ausnahmebedingung
      vorkommt. Wenn diese Ausnahmebedingungen nicht behandelt und entsprechende
      Maßnahmen eingeleitet werden, stürzt Ihre Express-Anwendung ab und geht
      offline. Wenn Sie dem nachfolgenden Rat in
      <a href="#restart"
        >Sicherstellen, dass Ihre Anwendung automatisch neu gestartet wird</a
      >
      folgen, wird Ihre Anwendung nach einem Absturz wiederhergestellt.
      Glücklicherweise haben Express-Anwendungen nur eine kurze
      Initialisierungszeit. Nichtsdestotrotz sollten Sie in erster Linie solche
      Abstürze vermeiden. Und hierzu müssen Sie Ausnahmebedingungen
      ordnungsgemäß handhaben.
    </p>
    <p>
      Mit folgenden Verfahren stellen Sie sicher, dass alle Ausnahmebedingungen
      gehandhabt werden:
    </p>
    <ul>
      <li><a href="#try-catch">“try-catch” verwenden</a></li>
      <li><a href="#promises">“Promises” verwenden</a></li>
    </ul>
    <p>
      Um näher auf diese Themen eingehen zu können, müssen Sie sich ein
      grundlegendes Verständnis der Fehlerbehandlung in Node und Express
      aneignen: Verwendung von Error-first-Callbacks und Propagieren von Fehlern
      in Middleware. Node verwendet die Konvention “Error-first-Callback” für
      die Rückgabe von Fehlern von asynchronen Funktionen, bei denen der erste
      Parameter zur Callback-Funktion das Fehlerobjekt ist, gefolgt von
      Ergebnisdaten in den nachfolgenden Parametern. Um anzugeben, dass kein
      Fehler vorliegt, müssen Sie “null” als ersten Parameter übergeben. Die
      Callback-Funktion muss der Konvention “Error-first-Callback” folgen, um
      den Fehler sinnvoll bearbeiten zu können. In Express hat sich bewährt, die
      Funktion “next()” zu verwenden, um Fehler über die Middleware-Chain zu
      propagieren.
    </p>
    <p>Weitere Informationen zu den Grundlagen der Fehlerbehandlung siehe:</p>
    <ul>
      <li>
        <a href="https://www.joyent.com/developers/node/design/errors"
          >Fehlerbehandlung in Node.js</a
        >
      </li>
      <li>
        <a
          href="https://strongloop.com/strongblog/robust-node-applications-error-handling/"
          >Aufbau leistungsfähiger Node-Anwendungen: Fehlerbehandlung</a
        >
        (StrongLoop-Blog)
      </li>
    </ul>
    <h4 id="was-sie-unterlassen-sollten">Was Sie unterlassen sollten</h4>
    <p>
      Sie sollten <em>auf keinen</em> Fall per Listener das Ereignis
      <code>uncaughtException</code> überwachen, das ausgegeben wird, wenn eine
      Ausnahmebedingung bis zurück zur Ereignisschleife bestehen bleibt. Durch
      das Hinzufügen eines Ereignislisteners für
      <code>uncaughtException</code> verändert sich das Standardverhalten des
      Prozesses, über das eine Ausnahmebedingung festgestellt wird. Der Prozess
      läuft dann trotz der Ausnahmebedingung weiter. Dies mag sich vielleicht
      gut anhören, um einem Absturz Ihrer Anwendung vorzubeugen. Das Ausführen
      einer Anwendung nach einer nicht abgefangenen Ausnahmebedingung ist aber
      eine durchaus riskante Vorgehensweise und wird nicht empfohlen, da der
      Prozessstatus störanfällig und unvorhersehbar wird.
    </p>
    <p>
      Außerdem wird die Verwendung von <code>uncaughtException</code> offiziell
      als
      <a
        href="https://nodejs.org/api/process.html#process_event_uncaughtexception"
        >grobes Vorgehen</a
      >
      angesehen, sodass es den
      <a href="https://github.com/nodejs/node-v0.x-archive/issues/2582"
        >Vorschlag</a
      >
      gibt, die Funktion aus dem Kern zu entfernen. Das Überwachen von
      <code>uncaughtException</code> per Listener ist also keine gute Idee.
      Daher empfehlen wir Dinge wie Mehrfachprozesse und Supervisoren: Ein
      Absturz und anschließender Neustart ist häufig die zuverlässigste Art der
      Fehlerbehebung.
    </p>
    <p>
      Zudem empfehlen wir,
      <a href="https://nodejs.org/api/domain.html">domains</a> nicht zu
      verwenden. Mit diesem Modul, das zudem veraltet ist, lässt sich das
      Problem in der Regel nicht lösen.
    </p>
    <p><a name="try-catch"></a></p>
    <h4 id="try-catch-verwenden">“try-catch” verwenden</h4>
    <p>
      “try-catch” ist ein JavaScript-Sprachkonstrukt, mit dem Sie
      Ausnahmebedingungen in synchronem Code abfangen können. Verwenden Sie
      “try-catch” beispielsweise, um JSON-Parsing-Fehler wie unten gezeigt zu
      bearbeiten.
    </p>
    <p>
      Verwenden Sie ein Tool wie <a href="http://jshint.com/">JSHint</a> oder
      <a href="http://www.jslint.com/">JSLint</a>, um implizite
      Ausnahmebedingungen wie
      <a href="http://www.jshint.com/docs/options/#undef"
        >Referenzfehler bei nicht definierten Variablen</a
      >
      zu finden.
    </p>
    <p>
      Dies ist ein Beispiel zur Verwendung von “try-catch”, um eine potenzielle
      “process-crashing”-Ausnahmebedingung zu handhaben. Diese
      Middlewarefunktion akzeptiert einen Abfragefeldparameter mit dem Namen
      “params”, der ein JSON-Objekt ist.
    </p>
    <pre>
<code class="language-javascript" translate="no">
app.get('/search', function (req, res) {
  // Simulating async operation
  setImmediate(function () {
    var jsonStr = req.query.params;
    try {
      var jsonObj = JSON.parse(jsonStr);
      res.send('Success');
    } catch (e) {
      res.status(400).send('Invalid JSON string');
    }
  });
});
</code>
</pre>
    <p>
      “try-catch” funktioniert jedoch nur in synchronem Code. Da die
      Node-Plattform primär asynchron ist (insbesondere in einer
      Produktionsumgebung), lassen sich mit “try-catch” nicht besonders viele
      Ausnahmebedingungen abfangen.
    </p>
    <p><a name="promises"></a></p>
    <h4 id="promises-verwenden">“Promises” verwenden</h4>
    <p>
      Mit “Promises” werden alle Ausnahmebedingungen (explizite und implizite)
      in asynchronen Codeblöcken gehandhabt, die <code>then()</code> verwenden.
      Sie müssen nur <code>.catch(next)</code> am Ende der Promises-Ketten
      hinzufügen. Beispiel:
    </p>
    <pre>
<code class="language-javascript" translate="no">
app.get('/', function (req, res, next) {
  // do some sync stuff
  queryDb()
    .then(function (data) {
      // handle data
      return makeCsv(data)
    })
    .then(function (csv) {
      // handle csv
    })
    .catch(next);
});

app.use(function (err, req, res, next) {
  // handle error
});
</code>
</pre>
    <p>
      Jetzt werden alle asynchronen und synchronen Fehler zur Middleware “error”
      propagiert.
    </p>
    <p>Es gibt jedoch zwei Vorbehalte:</p>
    <ol type="1">
      <li>
        Der gesamte asynchrone Code muss “Promises” zurückgeben (außer Emitter).
        Wenn eine bestimmte Bibliothek keine “Promises” zurückgibt, müssen Sie
        das Basisobjekt mit einer Helper-Funktion wie
        <a href="http://bluebirdjs.com/docs/api/promise.promisifyall.html"
          >Bluebird.promisifyAll()</a
        >
        konvertieren.
      </li>
      <li>
        Ereignisemitter (wie Streams) können nach wie vor nicht abgefangene
        Ausnahmebedingungen verursachen. Sie müssen also sicherstellen, dass Sie
        das Fehlerereignis ordnungsgemäß handhaben. Beispiel:
      </li>
    </ol>
    <pre>
<code class="language-javascript" translate="no">
app.get('/', wrap(async (req, res, next) => {
  let company = await getCompanyById(req.query.id)
  let stream = getLogoStreamById(company.id)
  stream.on('error', next).pipe(res)
}));
</code>
</pre>
    <p>
      Weitere Informationen zur Fehlerbehandlung mithilfe von “Promises” siehe:
    </p>
    <ul>
      <li>
        <a
          href="https://strongloop.com/strongblog/async-error-handling-expressjs-es7-promises-generators/"
          >Asynchrone Fehlerbehandlung in Express mit “Promises”, Generatoren
          und ES7</a
        >
      </li>
      <li>
        <a
          href="https://strongloop.com/strongblog/promises-in-node-js-with-q-an-alternative-to-callbacks/"
          >“Promises” in Node.js mit Q – eine Alternative zu Callbacks</a
        >
      </li>
    </ul>
    <p><a name="env"></a></p>
    <h2 id="empfehlungen-für-maßnahmen-an-ihrer-umgebungihrem-setup">
      Empfehlungen für Maßnahmen an Ihrer Umgebung/Ihrem Setup
    </h2>
    <p>
      Dies sind einige Beispiele für Maßnahmen, die Sie an Ihrer Systemumgebung
      vornehmen können, um die Anwendungsleistung zu verbessern:
    </p>
    <ul>
      <li>NODE_ENV auf “production” festlegen</li>
      <li>Automatischen Neustart Ihrer Anwendung sicherstellen</li>
      <li>Anwendung in einem Cluster ausführen</li>
      <li>Anforderungsergebnisse im Cache speichern</li>
      <li>Load Balancer verwenden</li>
      <li>Reverse Proxy verwenden</li>
    </ul>
    <h3 id="node_env-auf-production-festlegen">
      NODE_ENV auf “production” festlegen
    </h3>
    <p>
      In der Umgebungsvariablen NODE_ENV wird die Umgebung angegeben, in der
      eine Anwendung ausgeführt wird (in der Regel ist dies die Entwicklungs-
      oder Produktionsumgebung). Am einfachsten lässt sich die Leistung
      verbessern, indem NODE_ENV auf “production” festgelegt wird.
    </p>
    <p>
      Durch das Festlegen von NODE_ENV auf “production” führt Express Folgendes
      aus:
    </p>
    <ul>
      <li>Speichern von Anzeigevorlagen im Cache.</li>
      <li>
        Speichern von CSS-Dateien, die aus CSS-Erweiterungen generiert wurden,
        im Cache.
      </li>
      <li>Generieren von weniger ausführlichen Fehlernachrichten.</li>
    </ul>
    <p>
      <a
        href="http://apmblog.dynatrace.com/2015/07/22/the-drastic-effects-of-omitting-node_env-in-your-express-js-applications/"
        >Tests deuten darauf hin</a
      >, dass alleine dadurch die Anwendungsleistung um den Faktor 3 verbessert
      werden kann!
    </p>
    <p>
      Wenn Sie umgebungsspezifischen Code schreiben müssen, können Sie den Wert
      von NODE_ENV mit <code>process.env.NODE_ENV</code> überprüfen. Beachten
      Sie, dass die Überprüfung des Werts seiner Umgebungsvariablen eine
      leistungsbezogene Penalisierung nach sich zieht. Sie sollten also sehr
      sparsam damit umgehen.
    </p>
    <p>
      In einer Entwicklungsumgebung wird die Umgebungsvariable in der Regel in
      Ihrer interaktiven Shell festgelegt, indem Sie beispielsweise
      <code>export</code> oder Ihre Datei <code>.bash_profile</code> verwenden.
      Im Allgemeinen sollten Sie dies nicht auf dem Produktionsserver vornehmen.
      Verwenden Sie stattdessen das Init-System (systemd oder Upstart) Ihres
      Betriebssystems. Der nächste Abschnitt enthält weitere Details zur
      Verwendung des Init-Systems im Allgemeinen. Die Festlegung von NODE_ENV
      ist jedoch für das Leistungsverhalten so wichtig (und so einfach
      durchzuführen), dass hier besonders darauf eingegangen wird.
    </p>
    <p>
      Verwenden Sie bei Upstart das Schlüsselwort <code>env</code> in Ihrer
      Jobdatei. Beispiel:
    </p>
    <pre>
<code class="language-sh" translate="no">
# /etc/init/env.conf
 env NODE_ENV=production
</code>
</pre>
    <p>
      Weitere Informationen hierzu siehe
      <a href="http://upstart.ubuntu.com/cookbook/#environment-variables"
        >Upstart Intro, Cookbook and Best Practices</a
      >.
    </p>
    <p>
      Verwenden Sie bei systemd die Anweisung <code>Environment</code> in Ihrer
      Einheitendatei. Beispiel:
    </p>
    <pre>
<code class="language-sh" translate="no">
# /etc/systemd/system/myservice.service
Environment=NODE_ENV=production
</code>
</pre>
    <p>
      Weitere Informationen siehe
      <a
        href="https://coreos.com/os/docs/latest/using-environment-variables-in-systemd-units.html"
        >Umgebungsvariablen in systemd-Einheiten verwenden</a
      >.
    </p>
    <p>
      Wenn Sie StrongLoop Process Manager verwenden, können Sie auch die
      <a
        href="https://docs.strongloop.com/display/SLC/Setting+up+a+production+host#Settingupaproductionhost-Setenvironmentvariables"
        >Umgebungsvariable festlegen, wenn Sie StrongLoop Process Manager als
        Service installieren</a
      >.
    </p>
    <h3 id="automatischen-neustart-ihrer-anwendung-sicherstellen">
      Automatischen Neustart Ihrer Anwendung sicherstellen
    </h3>
    <p>
      In der Produktionsumgebung sollte die Anwendung nie offline sein. Das
      bedeutet, dass Sie sicherstellen müssen, dass die Anwendung bei einem
      Absturz der Anwendung oder des Servers immer wieder neu gestartet wird.
      Auch wenn man hofft, das keines dieser Ereignisse jemals eintritt, muss
      man doch mit beiden Möglichkeiten rechnen und:
    </p>
    <ul>
      <li>
        einen Prozessmanager verwenden, um die Anwendung (und Node) bei einem
        Absturz neu zu starten.
      </li>
      <li>
        das Init-System Ihres Betriebssystems verwenden, um den Prozessmanager
        bei einem Absturz des Betriebssystems neu zu starten. Außerdem kann das
        Init-System auch ohne einen Prozessmanager verwendet werden.
      </li>
    </ul>
    <p>
      Node-Anwendungen stürzen ab, wenn eine nicht abgefangene Ausnahmebedingung
      auftritt. Als Erstes müssen Sie in einem solchen Fall sicherstellen, dass
      Ihre Anwendung ausreichend getestet wurde und in der Lage ist, alle
      Ausnahmebedingungen zu handhaben (weitere Informationen siehe
      <a href="#exceptions">Ausnahmebedingungen ordnungsgemäß handhaben</a>).
      Die sicherste Maßnahme ist jedoch, einen Mechanismus zu implementieren,
      über den bei einem Absturz der Anwendung ein automatischer Neustart der
      Anwendung ausgeführt wird.
    </p>
    <h4 id="prozessmanager-verwenden">Prozessmanager verwenden</h4>
    <p>
      In Entwicklungumgebungen wird die Anwendung einfach über die Befehlszeile
      mit <code>node server.js</code> oder einer vergleichbaren Datei gestartet.
      In der Produktionsumgebung hingegen ist durch diese Vorgehensweise die
      Katastrophe bereits vorprogrammiert. Wenn die Anwendung abstürzt, ist sie
      solange offline, bis Sie sie erneut starten. Um sicherzustellen, dass Ihre
      Anwendung nach einem Absturz neu gestartet wird, sollten Sie einen
      Prozessmanager verwenden. Ein Prozessmanager ist ein “Container” für
      Anwendungen, der die Bereitstellung erleichtert, eine hohe Verfügbarkeit
      sicherstellt und die Verwaltung der Anwendung zur Laufzeit ermöglicht.
    </p>
    <p>
      Neben einem Neustart der Anwendung nach einem Absturz bietet ein
      Prozessmanager noch weitere Möglichkeiten:
    </p>
    <ul>
      <li>Einblicke in die Laufzeitleistung und die Ressourcennutzung</li>
      <li>
        Dynamische Änderung der Einstellungen zur Verbesserung des
        Leistungsverhaltens
      </li>
      <li>Steuerung des Clustering (StrongLoop PM und PM2)</li>
    </ul>
    <p>Die gängigsten Prozessmanager für Node sind:</p>
    <ul>
      <li><a href="http://strong-pm.io/">StrongLoop Process Manager</a></li>
      <li><a href="https://github.com/Unitech/pm2">PM2</a></li>
      <li><a href="https://www.npmjs.com/package/forever">Forever</a></li>
    </ul>
    <p>
      Einen Vergleich der Features und Funktionen dieser Prozessmanager finden
      Sie hier:
      <a href="http://strong-pm.io/compare/">http://strong-pm.io/compare/</a>.
      Eine ausführliche Einführung in diese drei Prozessmanager finden Sie hier:
      <a href="/%7B%7B%20page.lang%20%7D%7D/advanced/pm.html"
        >Prozessmanager für Express-Anwendungen</a
      >.
    </p>
    <p>
      Die Verwendung eines dieser Prozessmanager reicht aus, um Ihre Anwendung
      betriebsbereit zu halten, selbst wenn sie hin und wieder abstürzt.
    </p>
    <p>
      StrongLoop PM verfügt jedoch über zahlreiche Features und Funktionen, die
      sich speziell auf Implementierungen in der Produktionsumgebung beziehen.
      Sie können diesen Prozessmanager und die zugehörigen StrongLoop-Tools für
      folgende Zwecke verwenden:
    </p>
    <ul>
      <li>
        Lokales Erstellen und Packen Ihrer Anwendung mit anschließender sicherer
        Bereitstellung auf Ihrem Produktionssystem
      </li>
      <li>
        Automatischer Neustart Ihrer Anwendung nach einem Absturz aus
        irgendeinem Grund
      </li>
      <li>Verwaltung Ihrer Cluster über Fernzugriff</li>
      <li>
        Anzeige von CPU-Profilen und Heapspeichermomentaufnahmen
        (Heap-Snapshots) zur Optimierung der Leistung und Diagnose von
        Speicherlecks
      </li>
      <li>Anzeige von Leistungsmessdaten für Ihre Anwendung</li>
      <li>
        Einfache Skalierung auf mehrere Hosts mit integrierter Steuerung für
        Nginx Load Balancer
      </li>
    </ul>
    <p>
      Wie unten beschrieben, erfolgt ein automatischer Neustart beim
      Systemwiederanlauf, wenn Sie StrongLoop Process Manager über Ihr
      Init-System als Betriebssystemservice installieren. Dadurch bleiben Ihre
      Anwendungsprozesse und Cluster dauerhaft betriebsbereit.
    </p>
    <h4 id="init-system-verwenden">Init-System verwenden</h4>
    <p>
      Als nächste Ebene der Zuverlässigkeit müssen Sie sicherstellen, dass Ihre
      Anwendung bei einem Serverneustart neu gestartet wird. Systeme können
      immer wieder aus verschiedenen Gründen abstürzen. Um sicherzustellen, dass
      Ihre Anwendung bei einem Serverabsturz neu gestartet wird, können Sie das
      in Ihr Betriebssystem integrierte Init-System verwenden. Die beiden
      wichtigsten Init-Systeme sind aktuell
      <a href="https://wiki.debian.org/systemd">systemd</a> und
      <a href="http://upstart.ubuntu.com/">Upstart</a>.
    </p>
    <p>
      Es gibt zwei Möglichkeiten, Init-Systeme mit Ihrer Express-Anwendung zu
      verwenden:
    </p>
    <ul>
      <li>
        Ausführung Ihrer Anwendung in einem Prozessmanager und Installation des
        Prozessmanagers als Service mit dem Init-System. Der Prozessmanager wird
        neu gestartet, wenn Ihre Anwendung abstürzt. Das Init-System startet
        dann den Prozessmanager neu, sobald das Betriebssystem neu gestartet
        wird. Dies ist die empfohlene Vorgehensweise.
      </li>
      <li>
        Ausführung Ihrer Anwendung (und von Node) direkt mit dem Init-System.
        Diese Vorgehensweise ist zwar etwas einfacher, Sie profitieren jedoch
        nicht von den zusätzlichen Vorteilen des Einsatzes eines
        Prozessmanagers.
      </li>
    </ul>
    <h5 id="systemd">systemd</h5>
    <p>
      “systemd” ist ein Linux-System und Service-Manager. Die meisten wichtigen
      Linux-Distributionen haben “systemd” als Init-Standardsystem übernommen.
    </p>
    <p>
      Eine “systemd”-Servicekonfigurationsdatei wird als
      <em>Einheitendatei</em> bezeichnet, die die Endung “.service” hat. Dies
      ist ein Beispiel für eine Einheitendatei zur direkten Verwaltung einer
      Node-Anwendung (ersetzen Sie den Text in Fettdruck durch Werte für Ihr
      System und Ihre Anwendung):
    </p>
    <pre>
<code class="language-sh" translate="no">
[Unit]
Description=Awesome Express App

[Service]
Type=simple
ExecStart=/usr/local/bin/node /projects/myapp/index.js
WorkingDirectory=/projects/myapp

User=nobody
Group=nogroup

# Environment variables:
Environment=NODE_ENV=production

# Allow many incoming connections
LimitNOFILE=infinity

# Allow core dumps for debugging
LimitCORE=infinity

StandardInput=null
StandardOutput=syslog
StandardError=syslog
Restart=always

[Install]
WantedBy=multi-user.target
</code>
</pre>
    <p>
      Weitere Informationen zu “systemd” siehe
      <a
        href="http://www.freedesktop.org/software/systemd/man/systemd.unit.html"
        >systemd-Referenz (Man-Page)</a
      >. ##### StrongLoop Process Manager als “systemd”-Service
    </p>
    <p>
      Sie können StrongLoop Process Manager problemlos als “systemd”-Service
      installieren. Dadurch wird beim Serverneustart StrongLoop Process Manager
      automatisch neu gestartet. Dadurch wiederum werden alle Anwendungen neu
      gestartet, die von diesem Prozessmanager verwaltet werden.
    </p>
    <p>So installieren Sie StrongLoop Process Manager als “systemd”-Service:</p>
    <pre>
<code class="language-sh" translate="no">
$ sudo sl-pm-install --systemd
</code>
</pre>
    <p>Starten Sie dann den Service mit:</p>
    <pre>
<code class="language-sh" translate="no">
$ sudo /usr/bin/systemctl start strong-pm
</code>
</pre>
    <p>
      Weitere Informationen hierzu finden Sie im Thema
      <a
        href="https://docs.strongloop.com/display/SLC/Setting+up+a+production+host#Settingupaproductionhost-RHEL7+,Ubuntu15.04or15.10"
        >Produktionshost einrichten (in der StrongLoop-Dokumentation)</a
      >.
    </p>
    <h5 id="upstart">Upstart</h5>
    <p>
      “Upstart” ist ein Systemtool, das auf vielen Linux-Distributionen
      verfügbar ist. Mit diesem Tool können Aufgaben (Tasks) und Services beim
      Systemstart gestartet, beim Herunterfahren gestoppt und auch überwacht
      werden. Sie können Ihre Express-Anwendung oder einen Prozessmanager als
      Service konfigurieren. “Upstart” startet diese dann bei einem Absturz
      automatisch neu.
    </p>
    <p>
      Ein “Upstart”-Service wird als Jobkonfigurationsdatei (auch als “Job”
      bezeichnet) definiert, deren Dateiname mit <code>.conf</code> endet. Das
      folgende Beispiel zeigt, wie ein Job namens “myapp” für eine Anwendung
      namens “myapp” erstellt wird, wobei sich die Hauptdatei im Verzeichnis
      <code>/projects/myapp/index.js</code> befindet.
    </p>
    <p>
      Erstellen Sie eine Datei namens <code>myapp.conf</code> unter
      <code>/etc/init/</code> mit dem folgenden Inhalt (ersetzen Sie den Text in
      Fettdruck durch Werte für Ihr System und Ihre Anwendung):
    </p>
    <pre>
<code class="language-sh" translate="no">
# When to start the process
start on runlevel [2345]

# When to stop the process
stop on runlevel [016]

# Increase file descriptor limit to be able to handle more requests
limit nofile 50000 50000

# Use production mode
env NODE_ENV=production

# Run as www-data
setuid www-data
setgid www-data

# Run from inside the app dir
chdir /projects/myapp

# The process to start
exec /usr/local/bin/node /projects/myapp/index.js

# Restart the process if it is down
respawn

# Limit restart attempt to 10 times within 10 seconds
respawn limit 10 10
</code>
</pre>
    <p>
      Hinweis: Dieses Script erfordert Upstart 1.4 oder höher mit Unterstützung
      auf Ubuntu 12.04-14.10.
    </p>
    <p>
      Da der Job so konfiguriert ist, dass er beim Systemstart ausgeführt wird,
      wird Ihre Anwendung zusammen mit dem Betriebssystem gestartet und
      automatisch neu gestartet, wenn die Anwendung abstürzt oder das System
      heruntergefahren wird.
    </p>
    <p>
      Neben dem automatischen Neustart der Anwendung können Sie mit Upstart die
      folgenden Befehle verwenden:
    </p>
    <ul>
      <li><code>start myapp</code> – Anwendung starten</li>
      <li><code>restart myapp</code> – Anwendung neu starten</li>
      <li><code>stop myapp</code> – Anwendung stoppen</li>
    </ul>
    <p>
      Weitere Informationen zu “Upstart” siehe
      <a href="http://upstart.ubuntu.com/cookbook"
        >Upstart Intro, Cookbook and Best Practises</a
      >.
    </p>
    <h5 id="strongloop-process-manager-als-upstart-service">
      StrongLoop Process Manager als “Upstart”-Service
    </h5>
    <p>
      Sie können StrongLoop Process Manager problemlos als “Upstart”-Service
      installieren. Dadurch wird beim Serverneustart StrongLoop Process Manager
      automatisch neu gestartet. Dadurch wiederum werden alle Anwendungen neu
      gestartet, die von diesem Prozessmanager verwaltet werden.
    </p>
    <p>
      So installieren Sie StrongLoop Process Manager als “Upstart 1.4”-Service:
    </p>
    <pre>
<code class="language-sh" translate="no">
$ sudo sl-pm-install
</code>
</pre>
    <p>Fühen Sie dann den Service aus mit:</p>
    <pre>
<code class="language-sh" translate="no">
$ sudo /sbin/initctl start strong-pm
</code>
</pre>
    <p>
      Hinweis: Auf Systemen, die Upstart 1.4 nicht unterstützen, sind die
      Befehle leicht unterschiedlich. Weitere Informationen hierzu siehe das
      Thema
      <a
        href="https://docs.strongloop.com/display/SLC/Setting+up+a+production+host#Settingupaproductionhost-RHELLinux5and6,Ubuntu10.04-.10,11.04-.10"
        >Einrichtung eines Produktionshosts (in der StrongLoop-Dokumentation)</a
      >.
    </p>
    <h3 id="anwendung-in-einem-cluster-ausführen">
      Anwendung in einem Cluster ausführen
    </h3>
    <p>
      In einem Multi-Core-System können Sie die Leistung einer Node-Anwendung
      mehrmals erhöhen, indem Sie einen Cluster von Prozessen starten. Ein
      Cluster führt mehrere Instanzen der Anwendung aus, idealerweise eine
      Instanz auf jedem CPU-Core. Dadurch werden die Arbeitslasten und die Tasks
      auf die Instanzen verteilt.
    </p>
    <!--![Lastausgleich zwischen Anwendungsinstanzen mithilfe der Cluster-API](/images/clustering.png)-->
    <p>
      Wichtig. Da die Anwendungsinstanzen als separate Prozesse ausgeführt
      werden, nutzen sie nicht dieselbe Hauptspeicherkapazität gemeinsam. Das
      heißt, Objekte befinden sich für jede Instanz der Anwendung auf lokaler
      Ebene. Daher kann der Status im Anwendungscode nicht beibehalten werden.
      Sie können jedoch einen speicherinternen Datenspeicher wie
      <a href="http://redis.io/">Redis</a> verwenden, um sitzungsrelevante Daten
      und Statusinformationen zu speichern. Diese Einschränkung trifft im
      Wesentlichen auf alle Formen der horizontalen Skalierung zu, unabhängig
      davon, ob es sich um Clustering mit mehreren Prozessen oder mehreren
      physischen Servern handelt.
    </p>
    <p>
      Bei in Gruppen zusammengefassten Anwendungen (geclusterte Anwendungen)
      können Verarbeitungsprozesse einzeln ausfallen, ohne dass sich dies auf
      die restlichen Prozesse auswirkt. Neben den Leistungsvorteilen ist die
      Fehlerisolierung ein weiterer Grund, einen Cluster von Anwendungsprozessen
      auszuführen. Wenn ein Verarbeitungsprozess abstürzt, müssen Sie
      sicherstellen, dass das Ereignis protokolliert und ein neuer Prozess
      mithilfe von “cluster.fork()” gestartet wird.
    </p>
    <h4 id="clustermodule-von-node-verwenden">
      Clustermodule von Node verwenden
    </h4>
    <p>
      Das Clustering erfolgt über das
      <a href="https://nodejs.org/docs/latest/api/cluster.html">Clustermodul</a>
      von Node. Dadurch wird ein Masterprozess eingeleitet, um
      Verarbeitungsprozesse zu starten und eingehende Verbindungen auf die
      Verarbeitungsprozesse zu verteilen. Anstatt dieses Modul jedoch direkt zu
      verwenden, ist es deutlich besser, eines der vielen angebotenen Tools
      einzusetzen, das diesen Vorgang automatisch für Sie ausführt, wie
      beispielsweise
      <a href="https://www.npmjs.com/package/node-pm">node-pm</a> oder
      <a href="https://www.npmjs.com/package/cluster-service">cluster-service</a
      >.
    </p>
    <h4 id="strongloop-process-manager-verwenden">
      StrongLoop Process Manager verwenden
    </h4>
    <p>
      Wenn Sie Ihre Anwendung auf StrongLoop Process Manager (PM) bereitstellen,
      können Sie die Vorteile des Clustering nutzen, <em>ohne</em> Ihren
      Anwendungscode ändern zu müssen.
    </p>
    <p>
      Wenn StrongLoop Process Manager (PM) eine Anwendung ausführt, wird diese
      automatisch in einem Cluster ausgeführt. Die Anzahl der
      Verarbeitungsprozesse entspricht dabei der Anzahl der CPU-Cores im System.
      Sie können die Anzahl der Verarbeitungsprozesse manuell im Cluster ändern.
      Hierfür verwenden Sie das Befehlszeilentool “slc”, ohne die Anwendung
      stoppen zu müssen.
    </p>
    <p>
      Beispiel: Angenommen, Sie haben Ihre Anwendung auf prod.foo.com
      bereitgestellt, und StrongLoop PM ist auf Port 8701 (Standardport)
      empfangsbereit. Dann müssen Sie die Clustergröße mithilfe von “slc” auf
      “8” einstellen.
    </p>
    <pre>
<code class="language-sh" translate="no">
$ slc ctl -C http://prod.foo.com:8701 set-size my-app 8
</code>
</pre>
    <p>
      Weitere Informationen zum Clustering mit StrongLoop PM finden Sie im Thema
      <a href="https://docs.strongloop.com/display/SLC/Clustering"
        >Clustering</a
      >
      in der StrongLoop-Dokumentation.
    </p>
    <h3 id="anforderungsergebnisse-im-cache-speichern">
      Anforderungsergebnisse im Cache speichern
    </h3>
    <p>
      Eine weitere Strategie zur Verbesserung des Leistungsverhaltens in
      Produktionsumgebungen ist das Speichern von Anforderungergebnissen im
      Cache. Ihre Anwendung muss also diese Operation nicht wiederholt
      ausführen, um dieselbe Anforderung wiederholt zu bedienen.
    </p>
    <p>
      Mithilfe eines Caching-Servers wie
      <a href="https://www.varnish-cache.org/">Varnish</a> oder
      <a
        href="https://www.nginx.com/resources/wiki/start/topics/examples/reverseproxycachingexample/"
        >Nginx</a
      >
      (siehe auch
      <a href="https://serversforhackers.com/nginx-caching/">Nginx Caching</a>)
      lassen sich Geschwindigkeit und Leistung Ihrer Anwendung hervorragend
      verbessern.
    </p>
    <h3 id="load-balancer-verwenden">Load Balancer verwenden</h3>
    <p>
      Unabhängig davon, wie gut eine Anwendung optimiert wurde, kann eine
      Einzelinstanz nur eine begrenzte Arbeitslast oder einen begrenzten
      Datenverkehr handhaben. Eine Möglichkeit, eine Anwendung zu skalieren, ist
      die Ausführung mehrerer Instanzen dieser Anwendung und die Verteilung des
      Datenverkehrs über eine Lastausgleichsfunktion (Load Balancer)
      vorzunehmen. Die Einrichtung eines solchen Load Balancer kann helfen,
      Leistung und Geschwindigkeit Ihrer Anwendung zu verbessern. Zudem lässt
      sich dadurch die Anwendung besser skalieren als mit einer Einzelinstanz.
    </p>
    <p>
      Ein Load Balancer ist in der Regel ein Reverse Proxy, der den Datenverkehr
      zu und von mehreren Anwendungsinstanzen und Servern koordiniert. Sie
      können ohne großen Aufwand einen Load Balancer für Ihre Anwendung
      einrichten. Verwenden Sie hierzu
      <a href="http://nginx.org/en/docs/http/load_balancing.html">Nginx</a> oder
      <a
        href="https://www.digitalocean.com/community/tutorials/an-introduction-to-haproxy-and-load-balancing-concepts"
        >HAProxy</a
      >.
    </p>
    <p>
      Bei einer solchen Lastverteilung müssen Sie sicherstellen, dass
      Anforderungen, die einer bestimmten Sitzungs-ID zugeordnet sind, mit dem
      Prozess verbunden sind, von dem sie ursprünglich stammen. Dies wird auch
      als <em>Sitzungsaffinität</em> oder <em>Affine Sitzungen</em> bezeichnet
      und kann durch den obigen Vorschlag, einen Datenspeicher wie Redis für
      Sitzungsdaten zu verwenden (je nach Anwendung), umgesetzt werden. Eine
      Beschreibung hierzu siehe
      <a href="http://socket.io/docs/using-multiple-nodes/"
        >Mehrere Knoten verwenden</a
      >.
    </p>
    <h4 id="strongloop-process-manager-mit-einem-nginx-load-balancer-verwenden">
      StrongLoop Process Manager mit einem Nginx Load Balancer verwenden
    </h4>
    <p>
      <a href="http://strong-pm.io/">StrongLoop Process Manager</a> lässt sich
      in einen Nginx-Controller integrieren und erleichtert dadurch das
      Konfigurieren von Produktionsumgebungen mit mehreren Hosts. Weitere
      Informationen finden Sie im Thema zum
      <a
        href="https://docs.strongloop.com/display/SLC/Scaling+to+multiple+servers"
        >Skalieren auf mehrere Server</a
      >
      (in der StrongLoop-Dokumentation). <a name="proxy"></a>
    </p>
    <h3 id="reverse-proxy-verwenden">Reverse Proxy verwenden</h3>
    <p>
      Ein Reverse Proxy befindet sich vor einer Webanwendung und führt
      Unterstützungsoperationen für die Anforderungen aus (außer das
      Weiterleiten von Anforderungen an die Anwendung). Er kann u. a.
      Fehlerseiten, Komprimierungen und Caching bearbeiten, Dateien
      bereitstellen und Lastverteilungen vornehmen.
    </p>
    <p>
      Durch die Übergabe von Tasks, die keine Kenntnis des Anwendungsstatus
      erfordern, an einen Reverse Proxy muss Express keine speziellen
      Anwendungstasks mehr ausführen. Aus diesem Grund wird empfohlen, in
      Produktionsumgebungen Express hinter einem Reverse Proxy wie
      <a href="https://www.nginx.com/">Nginx</a> oder
      <a href="http://www.haproxy.org/">HAProxy</a> auszuführen.
    </p>
  </body>
</html>
