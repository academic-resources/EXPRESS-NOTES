<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ru" xml:lang="ru">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes"
    />
    <title>
      Лучшие практические методы улучшения производительности при использовании
      Express в рабочей среде
    </title>
    <style type="text/css">
      code {
        white-space: pre-wrap;
      }
      span.smallcaps {
        font-variant: small-caps;
      }
      span.underline {
        text-decoration: underline;
      }
      div.column {
        display: inline-block;
        vertical-align: top;
        width: 50%;
      }
    </style>
  </head>
  <body>
    <header id="title-block-header">
      <h1 class="title">
        Лучшие практические методы улучшения производительности при
        использовании Express в рабочей среде
      </h1>
    </header>
    <h1
      id="лучшие-практические-методы-для-рабочей-среды-производительность-и-надежность"
    >
      Лучшие практические методы для рабочей среды: производительность и
      надежность
    </h1>
    <h2 id="обзор">Обзор</h2>
    <p>
      В статье рассматриваются лучшие практические методы обеспечения
      производительности и надежности приложений Express, развернутых в рабочей
      среде.
    </p>
    <p>
      Рассматриваемая тема, без сомнения, относится к категории “DevOps”,
      которая рассматривает процесс традиционной разработки программного
      обеспечения во взаимосвязи с эксплуатацией. Соответственно, представленную
      в ней информацию можно разделить на две части:
    </p>
    <ul>
      <li><a href="#code">что можно сделать в коде</a> (разработка, Dev).</li>
      <li>
        <a href="#env">что можно сделать в среде / при настройке</a>
        (эксплуатация, Ops).
      </li>
    </ul>
    <p><a name="code"></a></p>
    <h2 id="что-можно-сделать-в-коде">Что можно сделать в коде</h2>
    <p>
      Ниже приведены некоторые примеры того, что можно сделать в коде для
      улучшения производительности приложений.
    </p>
    <ul>
      <li>Использовать сжатие gzip</li>
      <li>Не использовать синхронные функции</li>
      <li>
        Использовать промежуточные обработчики для обслуживания статических
        файлов
      </li>
      <li>Организовать корректное ведение протоколов</li>
      <li>Правильно обрабатывать исключительные ситуации</li>
    </ul>
    <h3 id="использовать-сжатие-gzip">Использовать сжатие gzip</h3>
    <p>
      Сжатие gzip может значительно уменьшить размер тела ответа и,
      соответственно, увеличить быстродействие веб-приложения. Используйте
      промежуточный обработчик для
      <a href="https://www.npmjs.com/package/compression">сжатия</a> gzip в
      приложениях Express. Например:
    </p>
    <pre>
<code class="language-javascript" translate="no">
var compression = require('compression');
var express = require('express');
var app = express();
app.use(compression());
</code>
</pre>
    <p>
      Для активно используемого веб-сайта в рабочей среде разумнее всего
      реализовать сжатие на уровне обратного прокси (см. раздел
      <a href="#proxy">Использование обратного прокси-сервера</a>). В этом
      случае можно обойтись без промежуточного обработчика для сжатия данных.
      Более подробная информация об активации сжатия в Nginx приведена в разделе
      <a href="http://nginx.org/en/docs/http/ngx_http_gzip_module.html"
        >Модуль сжатия ngx_http_gzip_module</a
      >
      документации по Nginx.
    </p>
    <h3 id="не-использовать-синхронные-функции">
      Не использовать синхронные функции
    </h3>
    <p>
      Синхронные функции и методы задерживают выполнение процесса до возвращения
      ответа. Один вызов синхронной функции может возвращать значение через
      несколько микросекунд или миллисекунд, однако в активно используемых
      веб-сайтах эти вызовы дают суммарный эффект снижения производительности
      приложения. В рабочей среде от них лучше отказаться.
    </p>
    <p>
      Модуль Node и многие другие модули поддерживают синхронную и асинхронную
      версию выполнения функций; однако в рабочей среде следует использовать
      только асинхронную версию. Синхронное выполнение функций может быть
      оправдано только при первоначальном запуске.
    </p>
    <p>
      При работе с Node.js 4.0+ или io.js 2.1.0+ можно воспользоваться флагом
      командной строки <code>--trace-sync-io</code>, который выводит
      предупреждение и трассировку стека, если в приложении используется
      синхронный API. В рабочей системе это, конечно, лишнее; скорее, это
      позволяет убедиться, что код готов для рабочей среды. Дополнительная
      информация приведена в разделе
      <a
        href="https://nodejs.org/en/blog/weekly-updates/weekly-update.2015-05-22/#2-1-0"
        >Еженедельное обновление io.js 2.1.0</a
      >.
    </p>
    <h3
      id="использовать-промежуточный-обработчик-для-обслуживания-статических-файлов"
    >
      Использовать промежуточный обработчик для обслуживания статических файлов
    </h3>
    <p>
      В среде разработки для обслуживания статических файлов можно использовать
      метод
      <a href="/%7B%7B%20page.lang%20%7D%7D/4x/api.html#res.sendFile"
        >res.sendFile()</a
      >. Для рабочей среды этот метод не подходит: при обработке каждого запроса
      файла он выполняет чтение из файловой системы, создавая большую задержку и
      снижая общую производительность приложения. Заметьте, что метод
      <code>res.sendFile()</code> <em>не</em> реализован для системного вызова
      <a href="http://linux.die.net/man/2/sendfile">sendfile</a>, который мог бы
      существенно повысить его эффективность.
    </p>
    <p>
      Рекомендуем воспользоваться промежуточным обработчиком
      <a href="https://www.npmjs.com/package/serve-static">serve-static</a> (или
      аналогичным ему), оптимизированным для обслуживания файлов приложений
      Express.
    </p>
    <p>
      Еще лучше воспользоваться для обслуживания статических файлов обратным
      прокси; дополнительная информация приведена в разделе
      <a href="#proxy">Использование обратного прокси-сервера</a>.
    </p>
    <h3 id="организовать-корректное-ведение-протоколов">
      Организовать корректное ведение протоколов
    </h3>
    <p>
      В целом вести протоколы работы приложения необходимо по двум причинам: в
      целях отладки и в целях регистрации работы приложения (по сути, сюда
      относится все остальное). На этапе разработки, сообщения протокола обычно
      выводят на терминал при помощи <code>console.log()</code> или
      <code>console.err()</code>. Но в случае вывода на терминал или в файл
      <a href="https://nodejs.org/api/console.html#console_console_1"
        >эти функции выполняются синхронно,</a
      >
      поэтому для рабочей среды они подойдут только при условии вывода в другую
      программу.
    </p>
    <h4 id="в-целях-отладки">В целях отладки</h4>
    <p>
      При ведении протокола в целях отладки рекомендуется вместо
      <code>console.log()</code> воспользоваться специальным отладочным модулем
      типа <a href="https://www.npmjs.com/package/debug">debug</a>. При работе с
      этим модулем можно использовать переменную среды DEBUG, которая
      определяет, какие отладочные сообщения будут переданы в
      <code>console.err()</code>. А для того чтобы приложения оставались чисто
      асинхронными, рекомендуется выводить результаты
      <code>console.err()</code> в другую программу. Но вы же не собираетесь
      заниматься отладкой в рабочей среде, верно?
    </p>
    <h4 id="в-целях-регистрации-работы-приложения">
      В целях регистрации работы приложения
    </h4>
    <p>
      Для регистрации работы приложения (например, учета переданных данных или
      отслеживания вызовов API-функций) можно вместо
      <code>console.log()</code> воспользоваться библиотекой регистрации типа
      <a href="https://www.npmjs.com/package/winston">Winston</a> или
      <a href="https://www.npmjs.com/package/bunyan">Bunyan</a>. Подробное
      сравнение двух библиотек проведено в корпоративном блоге StrongLoop
      <a
        href="https://strongloop.com/strongblog/compare-node-js-logging-winston-bunyan/"
        >Сравнение протоколирования Node.js с использованием Winston и Bunyan</a
      >.
    </p>
    <p><a name="exceptions"></a></p>
    <h3 id="правильно-обрабатывать-исключительные-ситуации">
      Правильно обрабатывать исключительные ситуации
    </h3>
    <p>
      При наступлении необрабатываемой исключительной ситуации в приложениях
      Node происходит сбой. Если не обрабатывать исключительные ситуации и не
      принимать необходимых мер, это приведет к сбою и отключению приложения
      Express. Рекомендация из следующего раздела
      <a href="#restart">Автоматический перезапуск приложения</a> поможет вам
      обеспечить восстановление приложения после сбоя. К счастью, приложения
      Express обычно имеют небольшое время запуска. Тем не менее, нужно
      позаботиться прежде всего о недопущении сбоев, для чего необходимо
      правильно обрабатывать исключительные ситуации.
    </p>
    <p>
      Для того чтобы в системе обрабатывались все исключительные ситуации, можно
      воспользоваться следующими методами:
    </p>
    <ul>
      <li><a href="#try-catch">метод try-catch</a></li>
      <li><a href="#promises">метод Promise</a></li>
    </ul>
    <p>
      Прежде чем перейти к этим темам, необходимо понимать основные принципы
      обработки ошибок в Node/Express: использование функции обратного вызова, в
      которой первый аргумент зарезервирован за объектом ошибки, и
      распространение ошибок в промежуточном обработчике. В Node принято
      соглашение “error-first callback” для возврата ошибок асинхронных функций:
      первый параметр любой функции обратного вызова всегда является
      объектом-ошибкой, за ним следуют параметры, содержащие результат
      обработки. Для того чтобы сообщить об ошибке, в качестве первого параметра
      передайте нуль. Для правильной обработки ошибки функция обратного вызова
      должна соответствующим образом выполнять соглашение “error-first
      callback”. В Express, как показала практика, лучший метод состоит в
      распространении ошибок по цепочке промежуточных обработчиков с
      использованием функции next().
    </p>
    <p>
      Более подробная информация об основных принципах обработки ошибок
      приведена в разделе:
    </p>
    <ul>
      <li>
        <a href="https://www.joyent.com/developers/node/design/errors"
          >Обработка ошибок в Node.js</a
        >
      </li>
      <li>
        <a
          href="https://strongloop.com/strongblog/robust-node-applications-error-handling/"
          >Разработка устойчивых к сбоям приложений Node: обработка ошибок</a
        >
        (корпоративный блог StrongLoop)
      </li>
    </ul>
    <h4 id="чего-не-нужно-делать">Чего не нужно делать</h4>
    <p>
      Вам точно <em>не</em> нужно обрабатывать событие
      <code>uncaughtException</code>, порожденное при передаче исключительной
      ситуации обратно в цикл ожидания событий. Добавление обработчика события
      <code>uncaughtException</code> изменит стандартное поведение процесса, в
      котором произошла исключительная ситуация; процесс продолжит выполнение,
      несмотря на исключительную ситуацию. На первый взгляд, это неплохой способ
      защиты от сбоя приложения. Однако выполнение приложения после того, как
      произошла необрабатываемая исключительная ситуация, весьма опасно само по
      себе и не может быть рекомендовано: состояние процесса становится
      ненадежным и непредсказуемым.
    </p>
    <p>
      Кроме того, использование <code>uncaughtException</code> официально
      считается
      <a
        href="https://nodejs.org/api/process.html#process_event_uncaughtexception"
        >crude</a
      >, и имеется вариант
      <a href="https://github.com/nodejs/node-v0.x-archive/issues/2582"
        >proposal</a
      >
      исключить его из ядра. Значит, обработка <code>uncaughtException</code> -
      идея неудачная. Поэтому мы и рекомендуем иметь несколько процессов и
      супервизоров: часто самым надежным способом восстановления после ошибки
      является удаление и перезапуск системы.
    </p>
    <p>
      Также мы не рекомендуем использовать модуль
      <a href="https://nodejs.org/api/domain.html">domains</a>. Он очень редко
      помогает решить проблему и является устаревшим.
    </p>
    <p><a name="try-catch"></a></p>
    <h4 id="метод-try-catch">Метод try-catch</h4>
    <p>
      Конструкция try-catch в языке JavaScript позволяет перехватывать
      исключительные ситуации в синхронном коде. Например, при помощи try-catch
      можно обрабатывать ошибки анализа JSON, как показано ниже.
    </p>
    <p>
      Инструменты типа <a href="http://jshint.com/">JSHint</a> или
      <a href="http://www.jslint.com/">JSLint</a> помогут вам найти неявные
      исключительные ситуации, подобные описанным в разделе
      <a href="http://www.jshint.com/docs/options/#undef"
        >Ошибки ReferenceError в неопределенных переменных</a
      >.
    </p>
    <p>
      Ниже приводится пример использования конструкции try-catch для обработки
      потенциальной исключительной ситуации, приводящей к отказу процесса. Этот
      промежуточный обработчик принимает параметр поля запроса “params”, который
      является объектом JSON.
    </p>
    <pre>
<code class="language-javascript" translate="no">
app.get('/search', function (req, res) {
  // Simulating async operation
  setImmediate(function () {
    var jsonStr = req.query.params;
    try {
      var jsonObj = JSON.parse(jsonStr);
      res.send('Success');
    } catch (e) {
      res.status(400).send('Invalid JSON string');
    }
  });
});
</code>
</pre>
    <p>
      Однако конструкция try-catch работает только для синхронного кода.
      Поскольку платформа Node является преимущественно асинхронной (в
      частности, в рабочей среде), с помощью конструкции try-catch удастся
      перехватить не так уж много исключительных ситуаций.
    </p>
    <p><a name="promises"></a></p>
    <h4 id="метод-promises">Метод Promises</h4>
    <p>
      Промисы (promises) обрабатывают любые исключительные ситуации (явные и
      неявные) в блоках асинхронного кода, в которых используется метод
      <code>then()</code>. Просто добавьте <code>.catch(next)</code> в конце
      цепочки промисов. Например:
    </p>
    <pre>
<code class="language-javascript" translate="no">
app.get('/', function (req, res, next) {
  // do some sync stuff
  queryDb()
    .then(function (data) {
      // handle data
      return makeCsv(data)
    })
    .then(function (csv) {
      // handle csv
    })
    .catch(next);
});

app.use(function (err, req, res, next) {
  // handle error
});
</code>
</pre>
    <p>
      Теперь все ошибки, асинхронные и синхронные, будут передаваться в
      промежуточный обработчик ошибок.
    </p>
    <p>Однако здесь необходимо разъяснить два момента:</p>
    <ol type="1">
      <li>
        Весь асинхронный код должен возвращать промисы (кроме отправителей).
        Если какая-то библиотека не возвращает промисы, преобразуйте объект base
        при помощи вспомогательной функции типа
        <a href="http://bluebirdjs.com/docs/api/promise.promisifyall.html"
          >Bluebird.promisifyAll()</a
        >.
      </li>
      <li>
        Отправители событий (такие как потоки) могут вызывать необрабатываемые
        исключительные ситуации. Поэтому проверьте правильность обработки
        событий ошибки; например:
      </li>
    </ol>
    <pre>
<code class="language-javascript" translate="no">
app.get('/', wrap(async (req, res, next) => {
  let company = await getCompanyById(req.query.id)
  let stream = getLogoStreamById(company.id)
  stream.on('error', next).pipe(res)
}))
</code>
</pre>
    <p>
      Дополнительная информация об обработке ошибок с использованием промисов
      приведена в разделе:
    </p>
    <ul>
      <li>
        <a
          href="https://strongloop.com/strongblog/async-error-handling-expressjs-es7-promises-generators/"
          >Обработка ошибок асинхронного кода в Express с использованием
          промисов, генераторов и ES7</a
        >
      </li>
      <li>
        <a
          href="https://strongloop.com/strongblog/promises-in-node-js-with-q-an-alternative-to-callbacks/"
          >Промисы в Node.js с Q - альтернатива функции обратного вызова</a
        >
      </li>
    </ul>
    <p><a name="env"></a></p>
    <h2 id="что-можно-сделать-в-среде-при-настройке">
      Что можно сделать в среде / при настройке
    </h2>
    <p>
      Ниже приведены некоторые примеры того, что можно сделать в среде
      функционирования системы для улучшения производительности приложений.
    </p>
    <ul>
      <li>Задать в переменной NODE_ENV значение “production”</li>
      <li>Обеспечить автоматический перезапуск приложения</li>
      <li>Выполнять приложение в кластере</li>
      <li>Сохранять результаты запросов в кэше</li>
      <li>Использовать распределитель нагрузки</li>
      <li>Использовать обратный прокси-сервер</li>
    </ul>
    <h3 id="задать-в-переменной-node_env-значение-production">
      Задать в переменной NODE_ENV значение “production”
    </h3>
    <p>
      Переменная среды NODE_ENV задает среду выполнения приложения (обычно это
      среда разработки или рабочая среда). Простейший способ улучшить
      производительность - задать в переменной NODE_ENV рабочую среду (значение
      “production”).
    </p>
    <p>Если NODE_ENV имеет значение “production”, то в Express:</p>
    <ul>
      <li>сохраняются в кэше шаблоны представления;</li>
      <li>сохраняются в кэше файлы CSS, сгенерированные из расширений CSS;</li>
      <li>генерируются менее подробные сообщения об ошибках.</li>
    </ul>
    <p>
      <a
        href="http://apmblog.dynatrace.com/2015/07/22/the-drastic-effects-of-omitting-node_env-in-your-express-js-applications/"
        >Тестирование показывает,</a
      >
      что в результате только этих действий производительность увеличивается
      втрое.
    </p>
    <p>
      Если вам необходимо написать код для определенной среды, значение
      переменной NODE_ENV можно проверить в <code>process.env.NODE_ENV</code>.
      Следует помнить, что при проверке значения любой переменной среды
      производительность снижается, поэтому желательно производить эту операцию
      пореже.
    </p>
    <p>
      В среде разработки переменные среды обычно указываются в интерактивной
      оболочке, например при помощи <code>export</code> или файла
      <code>.bash_profile</code>. На рабочем сервере лучше использовать систему
      инициализации ОС (systemd или Upstart). В следующем разделе мы уделим
      больше внимания системе инициализации в целом, но задание значения
      переменной NODE_ENV настолько важно для производительности (и при этом
      настолько легко достижимо), что рассматривается здесь отдельно.
    </p>
    <p>
      Для Upstart укажите в своем файле файле задания ключевое слово
      <code>env</code>. Например:
    </p>
    <pre>
<code class="language-sh" translate="no">
# /etc/init/env.conf
 env NODE_ENV=production
</code>
</pre>
    <p>
      Дополнительная информация приведена в разделе
      <a href="http://upstart.ubuntu.com/cookbook/#environment-variables"
        >Upstart: введение, справочное руководство и лучшие практические
        методы</a
      >.
    </p>
    <p>
      Для systemd укажите директиву <code>Environment</code> в своем файле
      юнитов. Например:
    </p>
    <pre>
<code class="language-sh" translate="no">
# /etc/systemd/system/myservice.service
Environment=NODE_ENV=production
</code>
</pre>
    <p>
      Дополнительная информация приведена в разделе
      <a
        href="https://coreos.com/os/docs/latest/using-environment-variables-in-systemd-units.html"
        >Использование переменных среды в юнитах systemd</a
      >.
    </p>
    <p>
      При работе с StrongLoop Process Manager можно также
      <a
        href="https://docs.strongloop.com/display/SLC/Setting+up+a+production+host#Settingupaproductionhost-Setenvironmentvariables"
        >задать переменную среды во время установки StrongLoop PM как службы</a
      >.
    </p>
    <h3 id="обеспечить-автоматический-перезапуск-приложения">
      Обеспечить автоматический перезапуск приложения
    </h3>
    <p>
      В рабочей среде приложение не должно отключатся ни при каких условиях.
      Следовательно, необходимо обеспечить его перезапуск не только при сбое
      самого приложения, но и при сбое сервера. Надеясь на то, что этого не
      случится, мы должны быть реалистами и на всякий случай подготовиться,
      чтобы:
    </p>
    <ul>
      <li>
        использовать диспетчер процессов для перезапуска приложения (и Node),
        когда произойдет его сбой;
      </li>
      <li>
        использовать систему инициализации ОС для перезапуска диспетчера
        процессов, когда произойдет сбой ОС. Систему инициализации можно
        использовать и без диспетчера процессов.
      </li>
    </ul>
    <p>
      При наступлении необрабатываемой исключительной ситуации в приложениях
      Node происходит сбой. Поэтому самое главное, что нужно сделать, -
      обеспечить, чтобы приложение было тщательно протестировано и обрабатывало
      все исключительные ситуации (дополнительная информация приведена в разделе
      <a href="#exceptions">Правильно обрабатывать исключительные ситуации</a>).
      А для устойчивости к отказам необходимо иметь механизм, который обеспечит
      автоматический перезапуск приложения, если произойдет его сбой.
    </p>
    <h4 id="использовать-диспетчер-процессов">
      Использовать диспетчер процессов
    </h4>
    <p>
      В среде разработки запустить приложение можно прямо из командной строки,
      указав <code>node server.js</code> или нечто подобное. В рабочей среде это
      верный путь к беде: в случае сбоя приложение будет отключено до тех пор,
      пока вы не выполните его перезапуск. Для того чтобы приложение
      перезапускалось после сбоя, используется диспетчер процессов. Диспетчер
      процессов - это “контейнер” для приложений, обеспечивающий развертывание и
      высокую готовность и позволяющий управлять приложением в среде выполнения.
    </p>
    <p>
      Помимо перезапуска приложения после сбоя, диспетчер процессов позволяет:
    </p>
    <ul>
      <li>
        получать аналитическую информацию о производительности среды выполнения
        и потреблении ресурсов;
      </li>
      <li>
        изменять параметры в динамическом режиме в целях повышения
        производительности;
      </li>
      <li>управлять кластеризацией (StrongLoop PM и pm2).</li>
    </ul>
    <p>Наиболее популярные диспетчеры процессов перечислены ниже:</p>
    <ul>
      <li><a href="http://strong-pm.io/">StrongLoop Process Manager</a></li>
      <li><a href="https://github.com/Unitech/pm2">PM2</a></li>
      <li><a href="https://www.npmjs.com/package/forever">Forever</a></li>
    </ul>
    <p>
      Сравнение трех диспетчеров процессов по каждой характеристике можно найти
      в разделе
      <a href="http://strong-pm.io/compare/">http://strong-pm.io/compare/</a>.
      Более подробное представление трех диспетчеров приведено в разделе
      <a href="/%7B%7B%20page.lang%20%7D%7D/advanced/pm.html"
        >Диспетчеры процессов для приложений Express</a
      >.
    </p>
    <p>
      Наличие любого из этих диспетчеров процессов позволит обеспечить
      работоспособность приложения даже в случае возможных сбоев.
    </p>
    <p>
      Однако StrongLoop PM имеет массу характеристик, рассчитанных специально на
      развертывание в среде выполнения. StrongLoop и связанные с ним инструменты
      позволяют:
    </p>
    <ul>
      <li>
        разрабатывать приложение и создавать его пакет в локальной системе и
        развертывать его в безопасном режиме в рабочей системе;
      </li>
      <li>
        автоматически перезапускать приложение после его сбоя независимо от
        причины;
      </li>
      <li>управлять кластерами в удаленном режиме;</li>
      <li>
        просматривать профайлы CPU и моментальные снимки кучи в целях
        оптимизации производительности и диагностирования утечек памяти;
      </li>
      <li>просматривать показатели производительности приложения;</li>
      <li>
        легко масштабировать для работы на нескольких хостах с возможностями
        встроенного управления распределителем нагрузки.
      </li>
    </ul>
    <p>
      Как объясняется ниже, при установке StrongLoop PM в качестве службы
      операционной системы с помощью системы инициализации, этот диспетчер будет
      автоматически выполнять перезапуск после перезагрузки системы. То есть,
      поддерживать постоянную активность процессов и кластеров.
    </p>
    <h4 id="использовать-систему-инициализации">
      Использовать систему инициализации
    </h4>
    <p>
      Следующий уровень надежности призван обеспечить перезапуск приложения при
      перезапуске сервера. Системы могут зависать по разным причинам. Для
      перезапуска приложения в случае сбоя сервера используйте систему
      инициализации, встроенную в вашу ОС. На данный момент используются две
      основные системы инициализации -
      <a href="https://wiki.debian.org/systemd">systemd</a> и
      <a href="http://upstart.ubuntu.com/">Upstart</a>.
    </p>
    <p>
      Системы инициализации можно использовать с приложением Express двумя
      способами:
    </p>
    <ul>
      <li>
        запустите приложение в диспетчере процессов и установите диспетчер
        процессов как службу в системе инициализации. Диспетчер процессов будет
        перезапускать приложение в случае сбоя приложения, система инициализации
        будет перезапускать диспетчер процессов в случае перезапуска ОС. Это
        рекомендуемый способ;
      </li>
      <li>
        запустите приложение (и Node) прямо в системе инициализации. Этот способ
        немного проще, но он лишает вас дополнительного преимущества -
        возможности использовать диспетчер процессов.
      </li>
    </ul>
    <h5 id="systemd">Systemd</h5>
    <p>
      Systemd - менеджер системы и служб для Linux. В большинстве основных
      дистрибутивов Linux systemd принят в качестве системы инициализации по
      умолчанию.
    </p>
    <p>
      Файл конфигурации службы systemd имеет имя <em>unit file</em> с
      расширением .service. Ниже приведен пример файла юнитов для
      непосредственного управления приложением Node (вместо выделенного жирным
      шрифтом текста укажите значения для своей системы и приложения):
    </p>
    <pre>
<code class="language-sh" translate="no">
[Unit]
Description=Awesome Express App

[Service]
Type=simple
ExecStart=/usr/local/bin/node /projects/myapp/index.js
WorkingDirectory=/projects/myapp

User=nobody
Group=nogroup

# Environment variables:
Environment=NODE_ENV=production

# Allow many incoming connections
LimitNOFILE=infinity

# Allow core dumps for debugging
LimitCORE=infinity

StandardInput=null
StandardOutput=syslog
StandardError=syslog
Restart=always

[Install]
WantedBy=multi-user.target
</code>
</pre>
    <p>
      Дополнительная информация о systemd приведена в разделе
      <a
        href="http://www.freedesktop.org/software/systemd/man/systemd.unit.html"
        >Справочник по systemd (страница справки)</a
      >.
    </p>
    <h5 id="strongloop-pm-как-служба-systemd">
      StrongLoop PM как служба systemd
    </h5>
    <p>
      Диспетчер процессов StrongLoop можно легко установить как службу systemd.
      В этом случае во время перезапуска сервера автоматически выполняется
      перезапуск StrongLoop PM; он, в свою очередь, перезапускает все
      приложения, которыми он управляет.
    </p>
    <p>
      Для установки StrongLoop PM как службы systemd выполните следующие
      действия:
    </p>
    <pre>
<code class="language-sh" translate="no">
$ sudo sl-pm-install --systemd
</code>
</pre>
    <p>Затем запустите службу в следующем порядке:</p>
    <pre>
<code class="language-sh" translate="no">
$ sudo /usr/bin/systemctl start strong-pm
</code>
</pre>
    <p>
      Дополнительная информация приведена в разделе
      <a
        href="https://docs.strongloop.com/display/SLC/Setting+up+a+production+host#Settingupaproductionhost-RHEL7+,Ubuntu15.04or15.10"
        >Настройка хоста рабочей среды (документация по StrongLoop)</a
      >.
    </p>
    <h5 id="upstart">Upstart</h5>
    <p>
      Upstart - системный инструмент, доступный во многих дистрибутивах Linux;
      позволяет запускать задачи и службы во время запуска системы,
      останавливать их во время выключения и осуществлять наблюдение за их
      работой. Если приложение Express или диспетчер процессов настроен как
      служба, Upstart будет автоматически перезапускать их в случае сбоя.
    </p>
    <p>
      Служба Upstart определяется в файле конфигурации задания (другое название
      - “задание”) с расширением <code>.conf</code>. Ниже приведен пример
      создания задания “myapp” для приложения “myapp”, где главный файл
      находится в каталоге <code>/projects/myapp/index.js</code>.
    </p>
    <p>
      Создайте файл <code>myapp.conf</code> в каталоге
      <code>/etc/init/</code> со следующим содержимым (вместо выделенного жирным
      шрифтом текста укажите значения для своей системы и приложения):
    </p>
    <pre>
<code class="language-sh" translate="no">
# When to start the process
start on runlevel [2345]

# When to stop the process
stop on runlevel [016]

# Increase file descriptor limit to be able to handle more requests
limit nofile 50000 50000

# Use production mode
env NODE_ENV=production

# Run as www-data
setuid www-data
setgid www-data

# Run from inside the app dir
chdir /projects/myapp

# The process to start
exec /usr/local/bin/node /projects/myapp/index.js

# Restart the process if it is down
respawn

# Limit restart attempt to 10 times within 10 seconds
respawn limit 10 10
</code>
</pre>
    <p>
      ПРИМЕЧАНИЕ. Для этого сценария требуется Upstart 1.4 или старшей версии с
      поддержкой в Ubuntu 12.04-14.10.
    </p>
    <p>
      Поскольку задание настроено для выполнения при запуске системы, ваше
      приложение будет запускаться вместе с операционной системой и
      автоматически перезапускаться в случае сбоя приложения или зависания
      системы.
    </p>
    <p>
      Помимо автоматического перезапуска приложения, Upstart позволяет выполнять
      следующие команды:
    </p>
    <ul>
      <li><code>start myapp</code> - запуск приложения</li>
      <li><code>restart myapp</code> - перезапуск приложения</li>
      <li><code>stop myapp</code> - остановка приложения</li>
    </ul>
    <p>
      Дополнительная информация об Upstart приведена в разделе
      <a href="http://upstart.ubuntu.com/cookbook"
        >Upstart: введение, справочное руководство и лучшие практические
        методы</a
      >.
    </p>
    <h5 id="strongloop-pm-как-служба-upstart">
      StrongLoop PM как служба Upstart
    </h5>
    <p>
      Диспетчер процессов StrongLoop можно легко установить как службу Upstart.
      В этом случае во время перезапуска сервера автоматически выполняется
      перезапуск StrongLoop PM; он, в свою очередь, перезапускает все
      приложения, которыми он управляет.
    </p>
    <p>
      Для установки StrongLoop PM как службы Upstart 1.4 выполните следующие
      действия:
    </p>
    <pre>
<code class="language-sh" translate="no">
$ sudo sl-pm-install
</code>
</pre>
    <p>Затем запустите службу в следующем порядке:</p>
    <pre>
<code class="language-sh" translate="no">
$ sudo /sbin/initctl start strong-pm
</code>
</pre>
    <p>
      ПРИМЕЧАНИЕ. В системах, не поддерживающих Upstart 1.4, команды будут иметь
      некоторые отличия. Дополнительная информация приведена в разделе
      <a
        href="https://docs.strongloop.com/display/SLC/Setting+up+a+production+host#Settingupaproductionhost-RHELLinux5and6,Ubuntu10.04-.10,11.04-.10"
        >Настройка хоста рабочей среды (документация по StrongLoop)</a
      >.
    </p>
    <h3 id="выполнять-приложение-в-кластере">
      Выполнять приложение в кластере
    </h3>
    <p>
      В многоядерных системах производительность приложения Node можно увеличить
      многократно, если запустить группу процессов. В группе выполняется
      несколько экземпляров приложения, в идеале - один экземпляр на каждом ядре
      ЦП, что позволяет распределять нагрузку и задачи по экземплярам.
    </p>
    <!--![Распределение нагрузки между экземплярами приложения с использованием API группы](/images/clustering.png)-->
    <p>
      ВАЖНОЕ ЗАМЕЧАНИЕ. Экземпляры приложения выполняются как отдельные
      процессы, поэтому они используют разные пространства памяти. То есть,
      объекты будут локальными для каждого экземпляра приложения. Значит, в коде
      приложения состояние не сохраняется. Зато можно использовать хранилище
      данных в оперативной памяти типа <a href="http://redis.io/">Redis</a>, в
      котором будут храниться связанные с сеансом данные и данные о состоянии.
      Эта оговорка относится по сути ко всем формам горизонтального
      масштабирования - в равной мере к и группам процессов, и к группам
      физических серверов.
    </p>
    <p>
      В кластерных приложениях сбой может произойти в процессах отдельного
      экземпляра приложения, не оказывая влияния на другие процессы. Помимо
      преимуществ улучшения производительности, изоляция сбоев также говорит в
      пользу выполнения процессов приложений в кластере. При любом сбое процесса
      экземпляра приложения обязательно занесите событие в протокол и породите
      новый процесс, используя метод cluster.fork().
    </p>
    <h4 id="использовать-модуль-cluster-node">
      Использовать модуль cluster Node
    </h4>
    <p>
      Поддержка кластеров возможна благодаря модулю Node
      <a href="https://nodejs.org/docs/latest/api/cluster.html"
        >cluster module</a
      >. Он позволяет главному процессу порождать процессы экземпляра приложения
      и распределять входящие соединения между экземплярами приложения. Но лучше
      использовать не сам этот модуль, а один из его инструментов, который будет
      выполнять необходимые действия автоматически, например
      <a href="https://www.npmjs.com/package/node-pm">node-pm</a> или
      <a href="https://www.npmjs.com/package/cluster-service">cluster-service</a
      >.
    </p>
    <h4 id="использовать-strongloop-pm">Использовать StrongLoop PM</h4>
    <p>
      Если приложение развернуто в диспетчере процессов StrongLoop Process
      Manager (PM), вы можете пользоваться поддержкой кластеров,
      <em>не</em> изменяя код приложения.
    </p>
    <p>
      Когда диспетчер процессов StrongLoop Process Manager (PM) выполняет
      приложение, то приложение автоматически будет выполняться в кластере с
      числом экземпляров приложения, равным числу ядер ЦП в системе. В кластере
      число процессов экземпляра приложения невозможно изменить вручную при
      помощи инструмента командной строки slc без остановки приложения.
    </p>
    <p>
      Например, если вы развернули приложение на prod.foo.com и StrongLoop PM
      слушает соединения на порте 8701 (значение по умолчанию), укажите размер
      кластера, равный восьми, используя slc:
    </p>
    <pre>
<code class="language-sh" translate="no">
$ slc ctl -C http://prod.foo.com:8701 set-size my-app 8
</code>
</pre>
    <p>
      Дополнительная информация о поддержке кластеров при помощи StrongLoop PM
      приведена в разделе
      <a href="https://docs.strongloop.com/display/SLC/Clustering"
        >Кластеризация</a
      >
      документации по StrongLoop.
    </p>
    <h3 id="сохранять-результаты-запросов-в-кэше">
      Сохранять результаты запросов в кэше
    </h3>
    <p>
      Еще одна стратегия улучшения производительности в рабочей среде
      заключается в том, чтобы сохранять в кэше результат запросов, тогда
      приложению не нужно будет повторять операцию для многократного
      обслуживания этого запроса.
    </p>
    <p>
      Используйте сервер кэширования типа
      <a href="https://www.varnish-cache.org/">Varnish</a> или
      <a
        href="https://www.nginx.com/resources/wiki/start/topics/examples/reverseproxycachingexample/"
        >Nginx</a
      >
      (см. также
      <a href="https://serversforhackers.com/nginx-caching/"
        >Кэширование Nginx</a
      >), чтобы существенно увеличить быстродействие и производительность своего
      приложения.
    </p>
    <h3 id="использовать-распределитель-нагрузки">
      Использовать распределитель нагрузки
    </h3>
    <p>
      Вне зависимости от оптимизации приложения отдельный экземпляр может
      обработать лишь определенную часть рабочей нагрузки и передаваемых данных.
      Один из способов масштабирования приложения состоит в запуске нескольких
      его экземпляров и распределении передаваемых данных при помощи
      распределителя нагрузки. Настройка распределителя нагрузки может улучшить
      производительность и быстродействие приложения и нарастить его возможности
      сверх того, что может делать один экземпляр приложения.
    </p>
    <p>
      Распределителем нагрузки обычно выступает обратный прокси-сервер, который
      управляет передачей данных между несколькими экземплярами приложений и
      серверами. Распределитель нагрузки приложения можно легко настроить при
      помощи
      <a href="http://nginx.org/en/docs/http/load_balancing.html">Nginx</a> или
      <a
        href="https://www.digitalocean.com/community/tutorials/an-introduction-to-haproxy-and-load-balancing-concepts"
        >HAProxy</a
      >.
    </p>
    <p>
      При работе с распределителем нагрузки рекомендуется убедиться, что
      запросы, связанные с определенным идентификатором сеанса, подключены к
      породившему их процессу. Это называется <em>привязка к сеансу</em> или
      <em>закрепленные сеансы</em>, и решается с помощью описанной выше
      рекомендации использовать для сеансовых данных хранилище данных типа Redis
      (в зависимости от приложения). Описание приведено в разделе
      <a href="http://socket.io/docs/using-multiple-nodes/"
        >Использовать несколько узлов</a
      >.
    </p>
    <h4 id="использовать-strongloop-pm-с-распределителем-нагрузки-nginx">
      Использовать StrongLoop PM с распределителем нагрузки Nginx
    </h4>
    <p>
      <a href="http://strong-pm.io/">StrongLoop Process Manager</a>
      интегрируется с Nginx Controller, позволяя легко настраивать конфигурации
      рабочих сред на нескольких хостах. Дополнительная информация приведена в
      разделе
      <a
        href="https://docs.strongloop.com/display/SLC/Scaling+to+multiple+servers"
        >Масштабирование на нескольких серверах</a
      >
      (документация по StrongLoop). <a name="proxy"></a>
    </p>
    <h3 id="использовать-обратный-прокси-сервер">
      Использовать обратный прокси-сервер
    </h3>
    <p>
      Обратный прокси-сервер расположен перед веб-приложением. Помимо
      направления запросов к приложению, он выполняет операции поддержки
      запросов. В частности, он способен обрабатывать страницы ошибок, операции
      сжатия, кэширования, обслуживания файлов и распределения нагрузки.
    </p>
    <p>
      Передача задач, для которых не требуется знать состояние приложения,
      обратному прокси-серверу разгружает Express для выполнения
      специализированных прикладных задач. В связи с этим в рабочей среде
      рекомендуется располагать Express за обратным прокси-сервером типа
      <a href="https://www.nginx.com/">Nginx</a> или
      <a href="http://www.haproxy.org/">HAProxy</a>.
    </p>
  </body>
</html>
